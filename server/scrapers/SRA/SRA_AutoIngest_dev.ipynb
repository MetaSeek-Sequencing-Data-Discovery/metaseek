{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto ingestion of SRA metadata\n",
    "\n",
    "1. Get a list of SRA UIDs to scrape\n",
    "    1. get all publically accessible SRA (SRX) accessions\n",
    "    2. remove SRA UIDs already been ingested into MetaSeek DB (all 'source_db_uid' where 'source_db' = 'SRA'\n",
    "    \n",
    "2. Split UIDs to scrape into batches of 500\n",
    "\n",
    "3. For each batch, scrape metadata:\n",
    "    1. efetch scrape SRA\n",
    "    2. elink to BioSample, Pubmed, Nuccore\n",
    "    3. efetch scrape BioSample, if exists\n",
    "    4. efetch scrape Pubmed, if exists\n",
    "    5. efetch scrape nuccore, if exists\n",
    "    \n",
    "4. Merge redundant cols to MIxS-compliant MetaSeek fields (separate script)\n",
    "\n",
    "5. Parse fields with controlled vocabularies to MIxS CV, if possible (NOTE: future error parsing)\n",
    "\n",
    "6. Insert scraped data into MetaSeek DB directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.A - Get a list of SRA UIDs to scrape\n",
    "\n",
    "* find out how many publicly available samples there are; make list retstarts to use \n",
    "* Call esearch api, with rotating retstarts, to get full UID list\n",
    "\n",
    "NOTE - most comprehensive API call to find ALL the SRA samples I can find (since an empty search term returns no accessions, not all) is term=public&field=ACS; returns all publically accessible SRA UIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_retstart_list(url):\n",
    "    #define retstarts need for get_uid_list eutilities requests - since can only get 100,000 at a time, need to make multiple queries to get total list\n",
    "    #find out count of UIDs going to pull from SRA\n",
    "    g = urllib.urlopen(url)\n",
    "    count_tree = etree.parse(g)\n",
    "    g.close()\n",
    "    count_xml = count_tree.getroot()\n",
    "    num_uids = count_xml.findtext(\"Count\")\n",
    "    print 'number of publicly available UIDs in SRA: %s' % num_uids\n",
    "    num_queries = 1+int(num_uids)/100000  #number of queries to do, with shifting retstart\n",
    "    retstart_list = [i*100000 for i in range(num_queries)]\n",
    "    print 'retstarts to use: %s' % retstart_list\n",
    "    return retstart_list\n",
    "\n",
    "def get_uid_list(ret_list):\n",
    "    #scrape UIDs into list\n",
    "    uid_list = []\n",
    "    for retstart in ret_list:\n",
    "        f = urllib.urlopen('https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=sra&term=public&field=ACS&tool=metaseq&email=metaseekcloud%40gmail.com&retmax=100000&retstart='+str(retstart))\n",
    "        uid_tree = etree.parse(f)\n",
    "        f.close()\n",
    "        uid_xml = uid_tree.getroot()\n",
    "        print \"appending %s accessions\" % len(uid_xml.find(\"IdList\").findall(\"Id\"))\n",
    "        #add uids to list of accessions\n",
    "        for id in uid_xml.find(\"IdList\").iterchildren():\n",
    "            value = id.text\n",
    "            uid_list.append(value)\n",
    "    return uid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of publicly available UIDs in SRA: 2694787\n",
      "retstarts to use: [0, 100000, 200000, 300000, 400000, 500000, 600000, 700000, 800000, 900000, 1000000, 1100000, 1200000, 1300000, 1400000, 1500000, 1600000, 1700000, 1800000, 1900000, 2000000, 2100000, 2200000, 2300000, 2400000, 2500000, 2600000]\n"
     ]
    }
   ],
   "source": [
    "retstart_list = get_retstart_list(url='https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=sra&term=public&field=ACS&rettype=count&tool=metaseq&email=metaseekcloud%40gmail.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 94787 accessions\n"
     ]
    }
   ],
   "source": [
    "uid_list = get_uid_list(ret_list=retstart_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO 1.B - Remove SRA UIDs already in in MetaSeek DB\n",
    "\n",
    "db_source_uid where db_source = 'SRA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Split UIDs to scrape into batches of 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_batches(uid_list):\n",
    "    starts = range(0,len(uid_list),500)\n",
    "    ends = range(500,len(uid_list),500)\n",
    "    ends.append(len(uid_list))\n",
    "    batches = [list(a) for a in zip(starts, ends)]\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches = get_batches(uid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5390\n",
      "[[0, 500], [500, 1000], [1000, 1500], [1500, 2000], [2000, 2500], [2500, 3000], [3000, 3500], [3500, 4000], [4000, 4500], [4500, 5000]]\n",
      "[[2690000, 2690500], [2690500, 2691000], [2691000, 2691500], [2691500, 2692000], [2692000, 2692500], [2692500, 2693000], [2693000, 2693500], [2693500, 2694000], [2694000, 2694500], [2694500, 2694787]]\n"
     ]
    }
   ],
   "source": [
    "print len(batches)\n",
    "print batches[0:10]\n",
    "print batches[-10:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.A - Efetch scrape SRA metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_srx_metadata(batch_uid_list):\n",
    "    print \"Querying API and parsing XML...\"\n",
    "    srx_url = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=sra&tool=metaseq&email=metaseekcloud%40gmail.com&id='+str(batch_uid_list)[1:-1]\n",
    "    s = urllib.urlopen(srx_url)\n",
    "    sra_tree = etree.parse(s)\n",
    "    s.close()\n",
    "    sra_xml = sra_tree.getroot()\n",
    "    print \"...parsing done!\"\n",
    "\n",
    "    sra_samples = sra_xml.findall(\"EXPERIMENT_PACKAGE\")\n",
    "    sdict = {}\n",
    "\n",
    "    for which,sra_sample in enumerate(sra_samples): #the order of experiment_packages ARE in order of sra ids given - that's good\n",
    "        print \"--scraping srx metadata for sample %s out of %s\" % (which+1,len(sra_samples))\n",
    "        srx_dict = {}\n",
    "\n",
    "        srx_uid = str(batch_uid_list[which])\n",
    "        srx_dict['db_source_uid'] = srx_uid\n",
    "        srx_dict['db_source'] = 'SRA'\n",
    "        srx_dict['expt_link'] = \"https://www.ncbi.nlm.nih.gov/sra/\"+str(srx_uid)\n",
    "\n",
    "        #There are 7 top tag groups. Have to scrape data a little different for each: ['EXPERIMENT','SUBMISSION','Organization','STUDY','SAMPLE','Pool','RUN_SET']\n",
    "\n",
    "        ###EXPERIMENT -\n",
    "        if sra_sample.find(\"EXPERIMENT\").find(\"IDENTIFIERS\").findtext(\"PRIMARY_ID\") is not None:\n",
    "            srx_dict['expt_id'] = sra_sample.find(\"EXPERIMENT\").find(\"IDENTIFIERS\").findtext(\"PRIMARY_ID\")\n",
    "        if sra_sample.find(\"EXPERIMENT\").findtext(\"TITLE\") is not None:\n",
    "            srx_dict['expt_title'] = sra_sample.find(\"EXPERIMENT\").findtext(\"TITLE\")\n",
    "        if sra_sample.find(\"EXPERIMENT\").find(\"STUDY_REF\").find(\"IDENTIFIERS\") is not None:\n",
    "            if sra_sample.find(\"EXPERIMENT\").find(\"STUDY_REF\").find(\"IDENTIFIERS\").findtext(\"PRIMARY_ID\") is not None:\n",
    "                srx_dict[\"project_id\"] = sra_sample.find(\"EXPERIMENT\").find(\"STUDY_REF\").find(\"IDENTIFIERS\").findtext(\"PRIMARY_ID\")   \n",
    "        if sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").findtext(\"DESIGN_DESCRIPTION\") is not None:\n",
    "            srx_dict['expt_design_description'] = sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").findtext(\"DESIGN_DESCRIPTION\")\n",
    "        if sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").find(\"SAMPLE_DESCRIPTOR\").find(\"IDENTIFIERS\").findtext(\"PRIMARY_ID\") is not None:\n",
    "            srx_dict['sample_id'] = sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").find(\"SAMPLE_DESCRIPTOR\").find(\"IDENTIFIERS\").findtext(\"PRIMARY_ID\")\n",
    "        if sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").find(\"LIBRARY_DESCRIPTOR\").findtext(\"LIBRARY_NAME\") is not None:\n",
    "            srx_dict['library_name'] = sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").find(\"LIBRARY_DESCRIPTOR\").findtext(\"LIBRARY_NAME\")\n",
    "        if sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").find(\"LIBRARY_DESCRIPTOR\").findtext(\"LIBRARY_STRATEGY\") is not None:\n",
    "            srx_dict['library_strategy'] = sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").find(\"LIBRARY_DESCRIPTOR\").findtext(\"LIBRARY_STRATEGY\")\n",
    "        if sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").find(\"LIBRARY_DESCRIPTOR\").findtext(\"LIBRARY_SOURCE\").lower() is not None:\n",
    "            srx_dict['library_source'] = sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").find(\"LIBRARY_DESCRIPTOR\").findtext(\"LIBRARY_SOURCE\").lower()\n",
    "        ###change library_selection to MIxS field library_screening_strategy (cv for SRA, not for MIxS)\n",
    "        if sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").find(\"LIBRARY_DESCRIPTOR\").findtext(\"LIBRARY_SELECTION\") is not None:\n",
    "            srx_dict['library_screening_strategy'] = sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").find(\"LIBRARY_DESCRIPTOR\").findtext(\"LIBRARY_SELECTION\")\n",
    "        ###change library_layout to MIxS field library_construction_method - cv single | paired\n",
    "        if sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").find(\"LIBRARY_DESCRIPTOR\").findtext(\"LIBRARY_LAYOUT\") is not None:\n",
    "            srx_dict['library_construction_method'] = sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").find(\"LIBRARY_DESCRIPTOR\").find(\"LIBRARY_LAYOUT\").getchildren()[0].tag.lower()\n",
    "        if sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").find(\"LIBRARY_DESCRIPTOR\").findtext(\"LIBRARY_CONSTRUCTION_PROTOCOL\") is not None:\n",
    "            srx_dict['library_construction_protocol'] = sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").find(\"LIBRARY_DESCRIPTOR\").findtext(\"LIBRARY_CONSTRUCTION_PROTOCOL\")\n",
    "        ###change platform to MIxS field sequencing_method - cv in SRA (not in MIxS)\n",
    "        if sra_sample.find(\"EXPERIMENT\").find(\"PLATFORM\").getchildren() is not None:\n",
    "            srx_dict['sequencing_method'] = sra_sample.find(\"EXPERIMENT\").find(\"PLATFORM\").getchildren()[0].tag.lower()\n",
    "            if sra_sample.find(\"EXPERIMENT\").find(\"PLATFORM\").getchildren()[0].findtext(\"INSTRUMENT_MODEL\") is not None:\n",
    "                srx_dict['instrument_model'] = sra_sample.find(\"EXPERIMENT\").find(\"PLATFORM\").getchildren()[0].findtext(\"INSTRUMENT_MODEL\")\n",
    "        \n",
    "        ###SUBMISSION - just need the submission id\n",
    "        if sra_sample.find(\"SUBMISSION\").find(\"IDENTIFIERS\").findtext(\"PRIMARY_ID\") is not None:\n",
    "            srx_dict['submission_id'] = sra_sample.find(\"SUBMISSION\").find(\"IDENTIFIERS\").findtext(\"PRIMARY_ID\")\n",
    "\n",
    "        ###Organization - name, address, and contact\n",
    "        if sra_sample.find(\"Organization\").findtext(\"Name\") is not None:\n",
    "            srx_dict['organization_name'] = sra_sample.find(\"Organization\").findtext(\"Name\")\n",
    "        if sra_sample.find(\"Organization\").find(\"Address\") is not None:\n",
    "            address = ''\n",
    "            for line in sra_sample.find(\"Organization\").find(\"Address\").iterchildren():\n",
    "                address = address+line.text+', '\n",
    "            address = address[:-2]\n",
    "            srx_dict['organization_address'] = address\n",
    "        if len(sra_sample.find(\"Organization\").findall(\"Contact\"))>0:\n",
    "            contacts = []\n",
    "            for contact in sra_sample.find(\"Organization\").findall(\"Contact\"):\n",
    "                name = contact.find(\"Name\").find(\"First\").text+' '+contact.find(\"Name\").find(\"Last\").text\n",
    "                email = contact.get('email')\n",
    "                contacts.append(name+', '+email)\n",
    "            srx_dict['organization_contacts'] = contacts\n",
    "        \n",
    "        ###STUDY -\n",
    "        if sra_sample.find(\"STUDY\").find(\"IDENTIFIERS\").findtext(\"PRIMARY_ID\") is not None: \n",
    "            srx_dict['study_id'] = sra_sample.find(\"STUDY\").find(\"IDENTIFIERS\").findtext(\"PRIMARY_ID\")\n",
    "        if len(sra_sample.find(\"STUDY\").find(\"IDENTIFIERS\").findall(\"EXTERNAL_ID\"))>0:\n",
    "            for external in sra_sample.find(\"STUDY\").find(\"IDENTIFIERS\").iterchildren(\"EXTERNAL_ID\"):\n",
    "                if external.get(\"namespace\")=='BioProject':\n",
    "                    srx_dict['bioproject_id'] = external.text\n",
    "        if sra_sample.find(\"STUDY\").find(\"DESCRIPTOR\").findtext(\"STUDY_TITLE\") is not None:\n",
    "            srx_dict['study_title'] = sra_sample.find(\"STUDY\").find(\"DESCRIPTOR\").findtext(\"STUDY_TITLE\")\n",
    "        ###rename existing_study_type to study_type\n",
    "        if sra_sample.find(\"STUDY\").find(\"DESCRIPTOR\").find(\"STUDY_TYPE\") is not None:\n",
    "            if sra_sample.find(\"STUDY\").find(\"DESCRIPTOR\").find(\"STUDY_TYPE\").get(\"existing_study_type\")==\"Other\":\n",
    "                srx_dict['study_type'] = 'Other'\n",
    "                if sra_sample.find(\"STUDY\").find(\"DESCRIPTOR\").find(\"STUDY_TYPE\").get(\"add_study_type\") is not None:\n",
    "                    srx_dict['study_type_other'] = sra_sample.find(\"STUDY\").find(\"DESCRIPTOR\").find(\"STUDY_TYPE\").get(\"add_study_type\")\n",
    "            else:\n",
    "                srx_dict['study_type'] = sra_sample.find(\"STUDY\").find(\"DESCRIPTOR\").find(\"STUDY_TYPE\").get(\"existing_study_type\")\n",
    "        if sra_sample.find(\"STUDY\").find(\"DESCRIPTOR\").findtext(\"STUDY_ABSTRACT\"):\n",
    "            srx_dict['study_abstract'] = sra_sample.find(\"STUDY\").find(\"DESCRIPTOR\").findtext(\"STUDY_ABSTRACT\")\n",
    "        if sra_sample.find(\"STUDY\").find(\"STUDY_LINKS\") is not None:\n",
    "            study_links = {}\n",
    "            for study_link in sra_sample.find(\"STUDY\").find(\"STUDY_LINKS\").iterchildren():\n",
    "                if study_link.find(\"XREF_LINK\") is not None:\n",
    "                    study_links[study_link.find(\"XREF_LINK\").findtext(\"DB\")] = study_link.find(\"XREF_LINK\").findtext(\"ID\")\n",
    "                if study_link.find(\"URL_LINK\") is not None:\n",
    "                    study_links[study_link.find(\"URL_LINK\").findtext(\"LABEL\")] = study_link.find(\"URL_LINK\").findtext(\"URL\")\n",
    "            srx_dict['study_links'] = study_links\n",
    "        if sra_sample.find(\"STUDY\").find(\"STUDY_ATTRIBUTES\") is not None:\n",
    "            study_attributes = {}\n",
    "            for attr in sra_sample.find(\"STUDY\").find(\"STUDY_ATTRIBUTES\").iterchildren():\n",
    "                study_attributes[attr.findtext(\"TAG\")] = attr.findtext(\"VALUE\")\n",
    "            srx_dict['study_attributes'] = study_attributes\n",
    "\n",
    "        ###SAMPLE - get some BioSample stuff that's in easier format here: sample id, biosample id (if exists; it should but sometimes doesn't); also title, sample name stuff, and description; rest get from biosample scraping\n",
    "        if sra_sample.find(\"SAMPLE\").find(\"IDENTIFIERS\").findtext(\"PRIMARY_ID\") is not None:\n",
    "            srx_dict['sample_id'] = sra_sample.find(\"SAMPLE\").find(\"IDENTIFIERS\").findtext(\"PRIMARY_ID\")\n",
    "        if len(sra_sample.find(\"SAMPLE\").find(\"IDENTIFIERS\").findall(\"EXTERNAL_ID\"))>0:\n",
    "            for external in sra_sample.find(\"SAMPLE\").find(\"IDENTIFIERS\").iterchildren(\"EXTERNAL_ID\"):\n",
    "                if external.get(\"namespace\")=='BioSample':\n",
    "                    srx_dict['biosample_id'] = external.text\n",
    "        if sra_sample.find(\"SAMPLE\").findtext(\"TITLE\") is not None:\n",
    "            srx_dict['sample_title'] = sra_sample.find(\"SAMPLE\").findtext(\"TITLE\")\n",
    "        if sra_sample.find(\"SAMPLE\").find(\"SAMPLE_NAME\") is not None: \n",
    "            if sra_sample.find(\"SAMPLE\").find(\"SAMPLE_NAME\").findtext(\"TAXON_ID\") is not None:\n",
    "                srx_dict['ncbi_taxon_id'] = sra_sample.find(\"SAMPLE\").find(\"SAMPLE_NAME\").findtext(\"TAXON_ID\")\n",
    "            if sra_sample.find(\"SAMPLE\").find(\"SAMPLE_NAME\").findtext(\"SCIENTIFIC_NAME\") is not None:\n",
    "                srx_dict['taxon_scientific_name'] = sra_sample.find(\"SAMPLE\").find(\"SAMPLE_NAME\").findtext(\"SCIENTIFIC_NAME\")\n",
    "            if sra_sample.find(\"SAMPLE\").find(\"SAMPLE_NAME\").findtext(\"COMMON_NAME\") is not None:\n",
    "                srx_dict['taxon_common_name'] = sra_sample.find(\"SAMPLE\").find(\"SAMPLE_NAME\").findtext(\"COMMON_NAME\")\n",
    "        if sra_sample.find(\"SAMPLE\").findtext(\"DESCRIPTION\") is not None: \n",
    "            srx_dict['sample_description'] = sra_sample.find(\"SAMPLE\").findtext(\"DESCRIPTION\")\n",
    "\n",
    "\n",
    "        ###Pool - skip, redundant\n",
    "\n",
    "        ###RUN_SET - record stats for each run as list, for best run (maxrun, run for which total_num_reads is largest) as single value\n",
    "        run_ids = []\n",
    "        total_num_reads = []\n",
    "        total_num_bases = []\n",
    "        download_size = []\n",
    "        avg_read_length = []\n",
    "        baseA_count = []\n",
    "        baseC_count = []\n",
    "        baseG_count = []\n",
    "        baseT_count = []\n",
    "        baseN_count = []\n",
    "        gc_percent = []\n",
    "        read_quality_counts = []\n",
    "\n",
    "        if len(sra_sample.find(\"RUN_SET\").findall(\"RUN\"))>0:\n",
    "            srx_dict['num_runs_in_accession'] = len(sra_sample.find(\"RUN_SET\").findall(\"RUN\"))\n",
    "            for run in sra_sample.find(\"RUN_SET\").findall(\"RUN\"):\n",
    "                run_ids.append(run.get(\"accession\"))\n",
    "                total_num_reads.append(int(run.get(\"total_spots\")))\n",
    "                total_num_bases.append(int(run.get(\"total_bases\")))\n",
    "                download_size.append(int(run.get(\"size\")))\n",
    "                avg_read_length.append(float(run.get(\"total_bases\"))/(float(run.find(\"Run\").get(\"spot_count\"))+float(run.find(\"Run\").get(\"spot_count_mates\"))))\n",
    "                for base in run.find(\"Bases\").findall(\"Base\"):\n",
    "                    if base.get(\"value\")==\"A\":\n",
    "                        baseA_count.append(int(base.get(\"count\")))\n",
    "                        countA = int(base.get(\"count\"))\n",
    "                    if base.get(\"value\")==\"C\":\n",
    "                        baseC_count.append(int(base.get(\"count\")))\n",
    "                        countC = int(base.get(\"count\"))\n",
    "                    if base.get(\"value\")==\"G\":\n",
    "                        baseG_count.append(int(base.get(\"count\")))\n",
    "                        countG = int(base.get(\"count\"))\n",
    "                    if base.get(\"value\")==\"T\":\n",
    "                        baseT_count.append(int(base.get(\"count\")))\n",
    "                        countT = int(base.get(\"count\"))\n",
    "                    if base.get(\"value\")==\"N\":\n",
    "                        baseN_count.append(int(base.get(\"count\")))\n",
    "                        countN = int(base.get(\"count\"))\n",
    "                gc_percent.append(float(countG+countC)/float(countC+countG+countA+countT))\n",
    "                qual_count = {}\n",
    "                if run.find(\"Run\").find(\"QualityCount\") is not None:\n",
    "                    for qual in run.find(\"Run\").find(\"QualityCount\").findall(\"Quality\"):\n",
    "                        qual_count[qual.get(\"value\")] = int(qual.get(\"count\"))\n",
    "                read_quality_counts.append(qual_count)\n",
    "\n",
    "\n",
    "            max_index = total_num_reads.index(max(total_num_reads))\n",
    "\n",
    "            srx_dict['run_ids'] = run_ids\n",
    "            srx_dict['run_ids_maxrun'] = run_ids[max_index]\n",
    "            srx_dict['total_num_reads'] = total_num_reads\n",
    "            srx_dict['total_num_reads_maxrun'] = total_num_reads[max_index]\n",
    "            srx_dict['total_num_bases'] = total_num_bases\n",
    "            srx_dict['total_num_bases_maxrun'] = total_num_bases[max_index]\n",
    "            srx_dict['download_size'] = download_size\n",
    "            srx_dict['download_size_maxrun'] = download_size[max_index]\n",
    "            srx_dict['avg_read_length'] = avg_read_length\n",
    "            srx_dict['avg_read_length_maxrun'] = avg_read_length[max_index]\n",
    "            srx_dict['baseA_count'] = baseA_count\n",
    "            srx_dict['baseA_count_maxrun'] = baseA_count[max_index]\n",
    "            srx_dict['baseC_count'] = baseC_count\n",
    "            srx_dict['baseC_count_maxrun'] = baseC_count[max_index]\n",
    "            srx_dict['baseG_count'] = baseG_count\n",
    "            srx_dict['baseG_count_maxrun'] = baseG_count[max_index]\n",
    "            srx_dict['baseT_count'] = baseT_count\n",
    "            srx_dict['baseT_count_maxrun'] = baseT_count[max_index]\n",
    "            srx_dict['baseN_count'] = baseN_count\n",
    "            srx_dict['baseN_count_maxrun'] = baseN_count[max_index]\n",
    "            srx_dict['gc_percent'] = gc_percent\n",
    "            srx_dict['gc_percent_maxrun'] = gc_percent[max_index]\n",
    "            srx_dict['read_quality_counts'] = read_quality_counts\n",
    "            srx_dict['read_quality_counts_maxrun'] = read_quality_counts[max_index]\n",
    "\n",
    "\n",
    "        sdict[srx_uid] = srx_dict\n",
    "\n",
    "    return sdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4124571,\n",
       " 4124570,\n",
       " 4124569,\n",
       " 4124568,\n",
       " 4124567,\n",
       " 4124566,\n",
       " 4124565,\n",
       " 4124564,\n",
       " 4124563,\n",
       " 4124562]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = batches[0]\n",
    "batch_uid_list = map(int,uid_list[batch[0]:batch[1]])\n",
    "print len(batch_uid_list)\n",
    "batch_uid_list[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying API and parsing XML...\n",
      "...parsing done!\n",
      "--scraping srx metadata for sample 1 out of 500\n",
      "--scraping srx metadata for sample 2 out of 500\n",
      "--scraping srx metadata for sample 3 out of 500\n",
      "--scraping srx metadata for sample 4 out of 500\n",
      "--scraping srx metadata for sample 5 out of 500\n",
      "--scraping srx metadata for sample 6 out of 500\n",
      "--scraping srx metadata for sample 7 out of 500\n",
      "--scraping srx metadata for sample 8 out of 500\n",
      "--scraping srx metadata for sample 9 out of 500\n",
      "--scraping srx metadata for sample 10 out of 500\n",
      "--scraping srx metadata for sample 11 out of 500\n",
      "--scraping srx metadata for sample 12 out of 500\n",
      "--scraping srx metadata for sample 13 out of 500\n",
      "--scraping srx metadata for sample 14 out of 500\n",
      "--scraping srx metadata for sample 15 out of 500\n",
      "--scraping srx metadata for sample 16 out of 500\n",
      "--scraping srx metadata for sample 17 out of 500\n",
      "--scraping srx metadata for sample 18 out of 500\n",
      "--scraping srx metadata for sample 19 out of 500\n",
      "--scraping srx metadata for sample 20 out of 500\n",
      "--scraping srx metadata for sample 21 out of 500\n",
      "--scraping srx metadata for sample 22 out of 500\n",
      "--scraping srx metadata for sample 23 out of 500\n",
      "--scraping srx metadata for sample 24 out of 500\n",
      "--scraping srx metadata for sample 25 out of 500\n",
      "--scraping srx metadata for sample 26 out of 500\n",
      "--scraping srx metadata for sample 27 out of 500\n",
      "--scraping srx metadata for sample 28 out of 500\n",
      "--scraping srx metadata for sample 29 out of 500\n",
      "--scraping srx metadata for sample 30 out of 500\n",
      "--scraping srx metadata for sample 31 out of 500\n",
      "--scraping srx metadata for sample 32 out of 500\n",
      "--scraping srx metadata for sample 33 out of 500\n",
      "--scraping srx metadata for sample 34 out of 500\n",
      "--scraping srx metadata for sample 35 out of 500\n",
      "--scraping srx metadata for sample 36 out of 500\n",
      "--scraping srx metadata for sample 37 out of 500\n",
      "--scraping srx metadata for sample 38 out of 500\n",
      "--scraping srx metadata for sample 39 out of 500\n",
      "--scraping srx metadata for sample 40 out of 500\n",
      "--scraping srx metadata for sample 41 out of 500\n",
      "--scraping srx metadata for sample 42 out of 500\n",
      "--scraping srx metadata for sample 43 out of 500\n",
      "--scraping srx metadata for sample 44 out of 500\n",
      "--scraping srx metadata for sample 45 out of 500\n",
      "--scraping srx metadata for sample 46 out of 500\n",
      "--scraping srx metadata for sample 47 out of 500\n",
      "--scraping srx metadata for sample 48 out of 500\n",
      "--scraping srx metadata for sample 49 out of 500\n",
      "--scraping srx metadata for sample 50 out of 500\n",
      "--scraping srx metadata for sample 51 out of 500\n",
      "--scraping srx metadata for sample 52 out of 500\n",
      "--scraping srx metadata for sample 53 out of 500\n",
      "--scraping srx metadata for sample 54 out of 500\n",
      "--scraping srx metadata for sample 55 out of 500\n",
      "--scraping srx metadata for sample 56 out of 500\n",
      "--scraping srx metadata for sample 57 out of 500\n",
      "--scraping srx metadata for sample 58 out of 500\n",
      "--scraping srx metadata for sample 59 out of 500\n",
      "--scraping srx metadata for sample 60 out of 500\n",
      "--scraping srx metadata for sample 61 out of 500\n",
      "--scraping srx metadata for sample 62 out of 500\n",
      "--scraping srx metadata for sample 63 out of 500\n",
      "--scraping srx metadata for sample 64 out of 500\n",
      "--scraping srx metadata for sample 65 out of 500\n",
      "--scraping srx metadata for sample 66 out of 500\n",
      "--scraping srx metadata for sample 67 out of 500\n",
      "--scraping srx metadata for sample 68 out of 500\n",
      "--scraping srx metadata for sample 69 out of 500\n",
      "--scraping srx metadata for sample 70 out of 500\n",
      "--scraping srx metadata for sample 71 out of 500\n",
      "--scraping srx metadata for sample 72 out of 500\n",
      "--scraping srx metadata for sample 73 out of 500\n",
      "--scraping srx metadata for sample 74 out of 500\n",
      "--scraping srx metadata for sample 75 out of 500\n",
      "--scraping srx metadata for sample 76 out of 500\n",
      "--scraping srx metadata for sample 77 out of 500\n",
      "--scraping srx metadata for sample 78 out of 500\n",
      "--scraping srx metadata for sample 79 out of 500\n",
      "--scraping srx metadata for sample 80 out of 500\n",
      "--scraping srx metadata for sample 81 out of 500\n",
      "--scraping srx metadata for sample 82 out of 500\n",
      "--scraping srx metadata for sample 83 out of 500\n",
      "--scraping srx metadata for sample 84 out of 500\n",
      "--scraping srx metadata for sample 85 out of 500\n",
      "--scraping srx metadata for sample 86 out of 500\n",
      "--scraping srx metadata for sample 87 out of 500\n",
      "--scraping srx metadata for sample 88 out of 500\n",
      "--scraping srx metadata for sample 89 out of 500\n",
      "--scraping srx metadata for sample 90 out of 500\n",
      "--scraping srx metadata for sample 91 out of 500\n",
      "--scraping srx metadata for sample 92 out of 500\n",
      "--scraping srx metadata for sample 93 out of 500\n",
      "--scraping srx metadata for sample 94 out of 500\n",
      "--scraping srx metadata for sample 95 out of 500\n",
      "--scraping srx metadata for sample 96 out of 500\n",
      "--scraping srx metadata for sample 97 out of 500\n",
      "--scraping srx metadata for sample 98 out of 500\n",
      "--scraping srx metadata for sample 99 out of 500\n",
      "--scraping srx metadata for sample 100 out of 500\n",
      "--scraping srx metadata for sample 101 out of 500\n",
      "--scraping srx metadata for sample 102 out of 500\n",
      "--scraping srx metadata for sample 103 out of 500\n",
      "--scraping srx metadata for sample 104 out of 500\n",
      "--scraping srx metadata for sample 105 out of 500\n",
      "--scraping srx metadata for sample 106 out of 500\n",
      "--scraping srx metadata for sample 107 out of 500\n",
      "--scraping srx metadata for sample 108 out of 500\n",
      "--scraping srx metadata for sample 109 out of 500\n",
      "--scraping srx metadata for sample 110 out of 500\n",
      "--scraping srx metadata for sample 111 out of 500\n",
      "--scraping srx metadata for sample 112 out of 500\n",
      "--scraping srx metadata for sample 113 out of 500\n",
      "--scraping srx metadata for sample 114 out of 500\n",
      "--scraping srx metadata for sample 115 out of 500\n",
      "--scraping srx metadata for sample 116 out of 500\n",
      "--scraping srx metadata for sample 117 out of 500\n",
      "--scraping srx metadata for sample 118 out of 500\n",
      "--scraping srx metadata for sample 119 out of 500\n",
      "--scraping srx metadata for sample 120 out of 500\n",
      "--scraping srx metadata for sample 121 out of 500\n",
      "--scraping srx metadata for sample 122 out of 500\n",
      "--scraping srx metadata for sample 123 out of 500\n",
      "--scraping srx metadata for sample 124 out of 500\n",
      "--scraping srx metadata for sample 125 out of 500\n",
      "--scraping srx metadata for sample 126 out of 500\n",
      "--scraping srx metadata for sample 127 out of 500\n",
      "--scraping srx metadata for sample 128 out of 500\n",
      "--scraping srx metadata for sample 129 out of 500\n",
      "--scraping srx metadata for sample 130 out of 500\n",
      "--scraping srx metadata for sample 131 out of 500\n",
      "--scraping srx metadata for sample 132 out of 500\n",
      "--scraping srx metadata for sample 133 out of 500\n",
      "--scraping srx metadata for sample 134 out of 500\n",
      "--scraping srx metadata for sample 135 out of 500\n",
      "--scraping srx metadata for sample 136 out of 500\n",
      "--scraping srx metadata for sample 137 out of 500\n",
      "--scraping srx metadata for sample 138 out of 500\n",
      "--scraping srx metadata for sample 139 out of 500\n",
      "--scraping srx metadata for sample 140 out of 500\n",
      "--scraping srx metadata for sample 141 out of 500\n",
      "--scraping srx metadata for sample 142 out of 500\n",
      "--scraping srx metadata for sample 143 out of 500\n",
      "--scraping srx metadata for sample 144 out of 500\n",
      "--scraping srx metadata for sample 145 out of 500\n",
      "--scraping srx metadata for sample 146 out of 500\n",
      "--scraping srx metadata for sample 147 out of 500\n",
      "--scraping srx metadata for sample 148 out of 500\n",
      "--scraping srx metadata for sample 149 out of 500\n",
      "--scraping srx metadata for sample 150 out of 500\n",
      "--scraping srx metadata for sample 151 out of 500\n",
      "--scraping srx metadata for sample 152 out of 500\n",
      "--scraping srx metadata for sample 153 out of 500\n",
      "--scraping srx metadata for sample 154 out of 500\n",
      "--scraping srx metadata for sample 155 out of 500\n",
      "--scraping srx metadata for sample 156 out of 500\n",
      "--scraping srx metadata for sample 157 out of 500\n",
      "--scraping srx metadata for sample 158 out of 500\n",
      "--scraping srx metadata for sample 159 out of 500\n",
      "--scraping srx metadata for sample 160 out of 500\n",
      "--scraping srx metadata for sample 161 out of 500\n",
      "--scraping srx metadata for sample 162 out of 500\n",
      "--scraping srx metadata for sample 163 out of 500\n",
      "--scraping srx metadata for sample 164 out of 500\n",
      "--scraping srx metadata for sample 165 out of 500\n",
      "--scraping srx metadata for sample 166 out of 500\n",
      "--scraping srx metadata for sample 167 out of 500\n",
      "--scraping srx metadata for sample 168 out of 500\n",
      "--scraping srx metadata for sample 169 out of 500\n",
      "--scraping srx metadata for sample 170 out of 500\n",
      "--scraping srx metadata for sample 171 out of 500\n",
      "--scraping srx metadata for sample 172 out of 500\n",
      "--scraping srx metadata for sample 173 out of 500\n",
      "--scraping srx metadata for sample 174 out of 500\n",
      "--scraping srx metadata for sample 175 out of 500\n",
      "--scraping srx metadata for sample 176 out of 500\n",
      "--scraping srx metadata for sample 177 out of 500\n",
      "--scraping srx metadata for sample 178 out of 500\n",
      "--scraping srx metadata for sample 179 out of 500\n",
      "--scraping srx metadata for sample 180 out of 500\n",
      "--scraping srx metadata for sample 181 out of 500\n",
      "--scraping srx metadata for sample 182 out of 500\n",
      "--scraping srx metadata for sample 183 out of 500\n",
      "--scraping srx metadata for sample 184 out of 500\n",
      "--scraping srx metadata for sample 185 out of 500\n",
      "--scraping srx metadata for sample 186 out of 500\n",
      "--scraping srx metadata for sample 187 out of 500\n",
      "--scraping srx metadata for sample 188 out of 500\n",
      "--scraping srx metadata for sample 189 out of 500\n",
      "--scraping srx metadata for sample 190 out of 500\n",
      "--scraping srx metadata for sample 191 out of 500\n",
      "--scraping srx metadata for sample 192 out of 500\n",
      "--scraping srx metadata for sample 193 out of 500\n",
      "--scraping srx metadata for sample 194 out of 500\n",
      "--scraping srx metadata for sample 195 out of 500\n",
      "--scraping srx metadata for sample 196 out of 500\n",
      "--scraping srx metadata for sample 197 out of 500\n",
      "--scraping srx metadata for sample 198 out of 500\n",
      "--scraping srx metadata for sample 199 out of 500\n",
      "--scraping srx metadata for sample 200 out of 500\n",
      "--scraping srx metadata for sample 201 out of 500\n",
      "--scraping srx metadata for sample 202 out of 500\n",
      "--scraping srx metadata for sample 203 out of 500\n",
      "--scraping srx metadata for sample 204 out of 500\n",
      "--scraping srx metadata for sample 205 out of 500\n",
      "--scraping srx metadata for sample 206 out of 500\n",
      "--scraping srx metadata for sample 207 out of 500\n",
      "--scraping srx metadata for sample 208 out of 500\n",
      "--scraping srx metadata for sample 209 out of 500\n",
      "--scraping srx metadata for sample 210 out of 500\n",
      "--scraping srx metadata for sample 211 out of 500\n",
      "--scraping srx metadata for sample 212 out of 500\n",
      "--scraping srx metadata for sample 213 out of 500\n",
      "--scraping srx metadata for sample 214 out of 500\n",
      "--scraping srx metadata for sample 215 out of 500\n",
      "--scraping srx metadata for sample 216 out of 500\n",
      "--scraping srx metadata for sample 217 out of 500\n",
      "--scraping srx metadata for sample 218 out of 500\n",
      "--scraping srx metadata for sample 219 out of 500\n",
      "--scraping srx metadata for sample 220 out of 500\n",
      "--scraping srx metadata for sample 221 out of 500\n",
      "--scraping srx metadata for sample 222 out of 500\n",
      "--scraping srx metadata for sample 223 out of 500\n",
      "--scraping srx metadata for sample 224 out of 500\n",
      "--scraping srx metadata for sample 225 out of 500\n",
      "--scraping srx metadata for sample 226 out of 500\n",
      "--scraping srx metadata for sample 227 out of 500\n",
      "--scraping srx metadata for sample 228 out of 500\n",
      "--scraping srx metadata for sample 229 out of 500\n",
      "--scraping srx metadata for sample 230 out of 500\n",
      "--scraping srx metadata for sample 231 out of 500\n",
      "--scraping srx metadata for sample 232 out of 500\n",
      "--scraping srx metadata for sample 233 out of 500\n",
      "--scraping srx metadata for sample 234 out of 500\n",
      "--scraping srx metadata for sample 235 out of 500\n",
      "--scraping srx metadata for sample 236 out of 500\n",
      "--scraping srx metadata for sample 237 out of 500\n",
      "--scraping srx metadata for sample 238 out of 500\n",
      "--scraping srx metadata for sample 239 out of 500\n",
      "--scraping srx metadata for sample 240 out of 500\n",
      "--scraping srx metadata for sample 241 out of 500\n",
      "--scraping srx metadata for sample 242 out of 500\n",
      "--scraping srx metadata for sample 243 out of 500\n",
      "--scraping srx metadata for sample 244 out of 500\n",
      "--scraping srx metadata for sample 245 out of 500\n",
      "--scraping srx metadata for sample 246 out of 500\n",
      "--scraping srx metadata for sample 247 out of 500\n",
      "--scraping srx metadata for sample 248 out of 500\n",
      "--scraping srx metadata for sample 249 out of 500\n",
      "--scraping srx metadata for sample 250 out of 500\n",
      "--scraping srx metadata for sample 251 out of 500\n",
      "--scraping srx metadata for sample 252 out of 500\n",
      "--scraping srx metadata for sample 253 out of 500\n",
      "--scraping srx metadata for sample 254 out of 500\n",
      "--scraping srx metadata for sample 255 out of 500\n",
      "--scraping srx metadata for sample 256 out of 500\n",
      "--scraping srx metadata for sample 257 out of 500\n",
      "--scraping srx metadata for sample 258 out of 500\n",
      "--scraping srx metadata for sample 259 out of 500\n",
      "--scraping srx metadata for sample 260 out of 500\n",
      "--scraping srx metadata for sample 261 out of 500\n",
      "--scraping srx metadata for sample 262 out of 500\n",
      "--scraping srx metadata for sample 263 out of 500\n",
      "--scraping srx metadata for sample 264 out of 500\n",
      "--scraping srx metadata for sample 265 out of 500\n",
      "--scraping srx metadata for sample 266 out of 500\n",
      "--scraping srx metadata for sample 267 out of 500\n",
      "--scraping srx metadata for sample 268 out of 500\n",
      "--scraping srx metadata for sample 269 out of 500\n",
      "--scraping srx metadata for sample 270 out of 500\n",
      "--scraping srx metadata for sample 271 out of 500\n",
      "--scraping srx metadata for sample 272 out of 500\n",
      "--scraping srx metadata for sample 273 out of 500\n",
      "--scraping srx metadata for sample 274 out of 500\n",
      "--scraping srx metadata for sample 275 out of 500\n",
      "--scraping srx metadata for sample 276 out of 500\n",
      "--scraping srx metadata for sample 277 out of 500\n",
      "--scraping srx metadata for sample 278 out of 500\n",
      "--scraping srx metadata for sample 279 out of 500\n",
      "--scraping srx metadata for sample 280 out of 500\n",
      "--scraping srx metadata for sample 281 out of 500\n",
      "--scraping srx metadata for sample 282 out of 500\n",
      "--scraping srx metadata for sample 283 out of 500\n",
      "--scraping srx metadata for sample 284 out of 500\n",
      "--scraping srx metadata for sample 285 out of 500\n",
      "--scraping srx metadata for sample 286 out of 500\n",
      "--scraping srx metadata for sample 287 out of 500\n",
      "--scraping srx metadata for sample 288 out of 500\n",
      "--scraping srx metadata for sample 289 out of 500\n",
      "--scraping srx metadata for sample 290 out of 500\n",
      "--scraping srx metadata for sample 291 out of 500\n",
      "--scraping srx metadata for sample 292 out of 500\n",
      "--scraping srx metadata for sample 293 out of 500\n",
      "--scraping srx metadata for sample 294 out of 500\n",
      "--scraping srx metadata for sample 295 out of 500\n",
      "--scraping srx metadata for sample 296 out of 500\n",
      "--scraping srx metadata for sample 297 out of 500\n",
      "--scraping srx metadata for sample 298 out of 500\n",
      "--scraping srx metadata for sample 299 out of 500\n",
      "--scraping srx metadata for sample 300 out of 500\n",
      "--scraping srx metadata for sample 301 out of 500\n",
      "--scraping srx metadata for sample 302 out of 500\n",
      "--scraping srx metadata for sample 303 out of 500\n",
      "--scraping srx metadata for sample 304 out of 500\n",
      "--scraping srx metadata for sample 305 out of 500\n",
      "--scraping srx metadata for sample 306 out of 500\n",
      "--scraping srx metadata for sample 307 out of 500\n",
      "--scraping srx metadata for sample 308 out of 500\n",
      "--scraping srx metadata for sample 309 out of 500\n",
      "--scraping srx metadata for sample 310 out of 500\n",
      "--scraping srx metadata for sample 311 out of 500\n",
      "--scraping srx metadata for sample 312 out of 500\n",
      "--scraping srx metadata for sample 313 out of 500\n",
      "--scraping srx metadata for sample 314 out of 500\n",
      "--scraping srx metadata for sample 315 out of 500\n",
      "--scraping srx metadata for sample 316 out of 500\n",
      "--scraping srx metadata for sample 317 out of 500\n",
      "--scraping srx metadata for sample 318 out of 500\n",
      "--scraping srx metadata for sample 319 out of 500\n",
      "--scraping srx metadata for sample 320 out of 500\n",
      "--scraping srx metadata for sample 321 out of 500\n",
      "--scraping srx metadata for sample 322 out of 500\n",
      "--scraping srx metadata for sample 323 out of 500\n",
      "--scraping srx metadata for sample 324 out of 500\n",
      "--scraping srx metadata for sample 325 out of 500\n",
      "--scraping srx metadata for sample 326 out of 500\n",
      "--scraping srx metadata for sample 327 out of 500\n",
      "--scraping srx metadata for sample 328 out of 500\n",
      "--scraping srx metadata for sample 329 out of 500\n",
      "--scraping srx metadata for sample 330 out of 500\n",
      "--scraping srx metadata for sample 331 out of 500\n",
      "--scraping srx metadata for sample 332 out of 500\n",
      "--scraping srx metadata for sample 333 out of 500\n",
      "--scraping srx metadata for sample 334 out of 500\n",
      "--scraping srx metadata for sample 335 out of 500\n",
      "--scraping srx metadata for sample 336 out of 500\n",
      "--scraping srx metadata for sample 337 out of 500\n",
      "--scraping srx metadata for sample 338 out of 500\n",
      "--scraping srx metadata for sample 339 out of 500\n",
      "--scraping srx metadata for sample 340 out of 500\n",
      "--scraping srx metadata for sample 341 out of 500\n",
      "--scraping srx metadata for sample 342 out of 500\n",
      "--scraping srx metadata for sample 343 out of 500\n",
      "--scraping srx metadata for sample 344 out of 500\n",
      "--scraping srx metadata for sample 345 out of 500\n",
      "--scraping srx metadata for sample 346 out of 500\n",
      "--scraping srx metadata for sample 347 out of 500\n",
      "--scraping srx metadata for sample 348 out of 500\n",
      "--scraping srx metadata for sample 349 out of 500\n",
      "--scraping srx metadata for sample 350 out of 500\n",
      "--scraping srx metadata for sample 351 out of 500\n",
      "--scraping srx metadata for sample 352 out of 500\n",
      "--scraping srx metadata for sample 353 out of 500\n",
      "--scraping srx metadata for sample 354 out of 500\n",
      "--scraping srx metadata for sample 355 out of 500\n",
      "--scraping srx metadata for sample 356 out of 500\n",
      "--scraping srx metadata for sample 357 out of 500\n",
      "--scraping srx metadata for sample 358 out of 500\n",
      "--scraping srx metadata for sample 359 out of 500\n",
      "--scraping srx metadata for sample 360 out of 500\n",
      "--scraping srx metadata for sample 361 out of 500\n",
      "--scraping srx metadata for sample 362 out of 500\n",
      "--scraping srx metadata for sample 363 out of 500\n",
      "--scraping srx metadata for sample 364 out of 500\n",
      "--scraping srx metadata for sample 365 out of 500\n",
      "--scraping srx metadata for sample 366 out of 500\n",
      "--scraping srx metadata for sample 367 out of 500\n",
      "--scraping srx metadata for sample 368 out of 500\n",
      "--scraping srx metadata for sample 369 out of 500\n",
      "--scraping srx metadata for sample 370 out of 500\n",
      "--scraping srx metadata for sample 371 out of 500\n",
      "--scraping srx metadata for sample 372 out of 500\n",
      "--scraping srx metadata for sample 373 out of 500\n",
      "--scraping srx metadata for sample 374 out of 500\n",
      "--scraping srx metadata for sample 375 out of 500\n",
      "--scraping srx metadata for sample 376 out of 500\n",
      "--scraping srx metadata for sample 377 out of 500\n",
      "--scraping srx metadata for sample 378 out of 500\n",
      "--scraping srx metadata for sample 379 out of 500\n",
      "--scraping srx metadata for sample 380 out of 500\n",
      "--scraping srx metadata for sample 381 out of 500\n",
      "--scraping srx metadata for sample 382 out of 500\n",
      "--scraping srx metadata for sample 383 out of 500\n",
      "--scraping srx metadata for sample 384 out of 500\n",
      "--scraping srx metadata for sample 385 out of 500\n",
      "--scraping srx metadata for sample 386 out of 500\n",
      "--scraping srx metadata for sample 387 out of 500\n",
      "--scraping srx metadata for sample 388 out of 500\n",
      "--scraping srx metadata for sample 389 out of 500\n",
      "--scraping srx metadata for sample 390 out of 500\n",
      "--scraping srx metadata for sample 391 out of 500\n",
      "--scraping srx metadata for sample 392 out of 500\n",
      "--scraping srx metadata for sample 393 out of 500\n",
      "--scraping srx metadata for sample 394 out of 500\n",
      "--scraping srx metadata for sample 395 out of 500\n",
      "--scraping srx metadata for sample 396 out of 500\n",
      "--scraping srx metadata for sample 397 out of 500\n",
      "--scraping srx metadata for sample 398 out of 500\n",
      "--scraping srx metadata for sample 399 out of 500\n",
      "--scraping srx metadata for sample 400 out of 500\n",
      "--scraping srx metadata for sample 401 out of 500\n",
      "--scraping srx metadata for sample 402 out of 500\n",
      "--scraping srx metadata for sample 403 out of 500\n",
      "--scraping srx metadata for sample 404 out of 500\n",
      "--scraping srx metadata for sample 405 out of 500\n",
      "--scraping srx metadata for sample 406 out of 500\n",
      "--scraping srx metadata for sample 407 out of 500\n",
      "--scraping srx metadata for sample 408 out of 500\n",
      "--scraping srx metadata for sample 409 out of 500\n",
      "--scraping srx metadata for sample 410 out of 500\n",
      "--scraping srx metadata for sample 411 out of 500\n",
      "--scraping srx metadata for sample 412 out of 500\n",
      "--scraping srx metadata for sample 413 out of 500\n",
      "--scraping srx metadata for sample 414 out of 500\n",
      "--scraping srx metadata for sample 415 out of 500\n",
      "--scraping srx metadata for sample 416 out of 500\n",
      "--scraping srx metadata for sample 417 out of 500\n",
      "--scraping srx metadata for sample 418 out of 500\n",
      "--scraping srx metadata for sample 419 out of 500\n",
      "--scraping srx metadata for sample 420 out of 500\n",
      "--scraping srx metadata for sample 421 out of 500\n",
      "--scraping srx metadata for sample 422 out of 500\n",
      "--scraping srx metadata for sample 423 out of 500\n",
      "--scraping srx metadata for sample 424 out of 500\n",
      "--scraping srx metadata for sample 425 out of 500\n",
      "--scraping srx metadata for sample 426 out of 500\n",
      "--scraping srx metadata for sample 427 out of 500\n",
      "--scraping srx metadata for sample 428 out of 500\n",
      "--scraping srx metadata for sample 429 out of 500\n",
      "--scraping srx metadata for sample 430 out of 500\n",
      "--scraping srx metadata for sample 431 out of 500\n",
      "--scraping srx metadata for sample 432 out of 500\n",
      "--scraping srx metadata for sample 433 out of 500\n",
      "--scraping srx metadata for sample 434 out of 500\n",
      "--scraping srx metadata for sample 435 out of 500\n",
      "--scraping srx metadata for sample 436 out of 500\n",
      "--scraping srx metadata for sample 437 out of 500\n",
      "--scraping srx metadata for sample 438 out of 500\n",
      "--scraping srx metadata for sample 439 out of 500\n",
      "--scraping srx metadata for sample 440 out of 500\n",
      "--scraping srx metadata for sample 441 out of 500\n",
      "--scraping srx metadata for sample 442 out of 500\n",
      "--scraping srx metadata for sample 443 out of 500\n",
      "--scraping srx metadata for sample 444 out of 500\n",
      "--scraping srx metadata for sample 445 out of 500\n",
      "--scraping srx metadata for sample 446 out of 500\n",
      "--scraping srx metadata for sample 447 out of 500\n",
      "--scraping srx metadata for sample 448 out of 500\n",
      "--scraping srx metadata for sample 449 out of 500\n",
      "--scraping srx metadata for sample 450 out of 500\n",
      "--scraping srx metadata for sample 451 out of 500\n",
      "--scraping srx metadata for sample 452 out of 500\n",
      "--scraping srx metadata for sample 453 out of 500\n",
      "--scraping srx metadata for sample 454 out of 500\n",
      "--scraping srx metadata for sample 455 out of 500\n",
      "--scraping srx metadata for sample 456 out of 500\n",
      "--scraping srx metadata for sample 457 out of 500\n",
      "--scraping srx metadata for sample 458 out of 500\n",
      "--scraping srx metadata for sample 459 out of 500\n",
      "--scraping srx metadata for sample 460 out of 500\n",
      "--scraping srx metadata for sample 461 out of 500\n",
      "--scraping srx metadata for sample 462 out of 500\n",
      "--scraping srx metadata for sample 463 out of 500\n",
      "--scraping srx metadata for sample 464 out of 500\n",
      "--scraping srx metadata for sample 465 out of 500\n",
      "--scraping srx metadata for sample 466 out of 500\n",
      "--scraping srx metadata for sample 467 out of 500\n",
      "--scraping srx metadata for sample 468 out of 500\n",
      "--scraping srx metadata for sample 469 out of 500\n",
      "--scraping srx metadata for sample 470 out of 500\n",
      "--scraping srx metadata for sample 471 out of 500\n",
      "--scraping srx metadata for sample 472 out of 500\n",
      "--scraping srx metadata for sample 473 out of 500\n",
      "--scraping srx metadata for sample 474 out of 500\n",
      "--scraping srx metadata for sample 475 out of 500\n",
      "--scraping srx metadata for sample 476 out of 500\n",
      "--scraping srx metadata for sample 477 out of 500\n",
      "--scraping srx metadata for sample 478 out of 500\n",
      "--scraping srx metadata for sample 479 out of 500\n",
      "--scraping srx metadata for sample 480 out of 500\n",
      "--scraping srx metadata for sample 481 out of 500\n",
      "--scraping srx metadata for sample 482 out of 500\n",
      "--scraping srx metadata for sample 483 out of 500\n",
      "--scraping srx metadata for sample 484 out of 500\n",
      "--scraping srx metadata for sample 485 out of 500\n",
      "--scraping srx metadata for sample 486 out of 500\n",
      "--scraping srx metadata for sample 487 out of 500\n",
      "--scraping srx metadata for sample 488 out of 500\n",
      "--scraping srx metadata for sample 489 out of 500\n",
      "--scraping srx metadata for sample 490 out of 500\n",
      "--scraping srx metadata for sample 491 out of 500\n",
      "--scraping srx metadata for sample 492 out of 500\n",
      "--scraping srx metadata for sample 493 out of 500\n",
      "--scraping srx metadata for sample 494 out of 500\n",
      "--scraping srx metadata for sample 495 out of 500\n",
      "--scraping srx metadata for sample 496 out of 500\n",
      "--scraping srx metadata for sample 497 out of 500\n",
      "--scraping srx metadata for sample 498 out of 500\n",
      "--scraping srx metadata for sample 499 out of 500\n",
      "--scraping srx metadata for sample 500 out of 500\n"
     ]
    }
   ],
   "source": [
    "sdict = get_srx_metadata(batch_uid_list=batch_uid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avg_read_length': [243.1248156205851],\n",
       " 'avg_read_length_maxrun': 243.1248156205851,\n",
       " 'baseA_count': [26718113],\n",
       " 'baseA_count_maxrun': 26718113,\n",
       " 'baseC_count': [35901728],\n",
       " 'baseC_count_maxrun': 35901728,\n",
       " 'baseG_count': [35257176],\n",
       " 'baseG_count_maxrun': 35257176,\n",
       " 'baseN_count': [54440],\n",
       " 'baseN_count_maxrun': 54440,\n",
       " 'baseT_count': [27006982],\n",
       " 'baseT_count_maxrun': 27006982,\n",
       " 'bioproject_id': 'PRJNA388450',\n",
       " 'biosample_id': 'SAMN07189570',\n",
       " 'db_source': 'SRA',\n",
       " 'db_source_uid': '4123344',\n",
       " 'download_size': [71321164],\n",
       " 'download_size_maxrun': 71321164,\n",
       " 'expt_design_description': '250 paired ends reads of fragmented DNA',\n",
       " 'expt_id': 'SRX2880321',\n",
       " 'expt_link': 'https://www.ncbi.nlm.nih.gov/sra/4123344',\n",
       " 'expt_title': 'whole genome sequencing of gram-negative bacteria',\n",
       " 'gc_percent': [0.5698000109685789],\n",
       " 'gc_percent_maxrun': 0.5698000109685789,\n",
       " 'instrument_model': 'Illumina MiSeq',\n",
       " 'library_construction_method': 'paired',\n",
       " 'library_name': 'MB750',\n",
       " 'library_screening_strategy': 'RANDOM',\n",
       " 'library_source': 'genomic',\n",
       " 'library_strategy': 'WGS',\n",
       " 'ncbi_taxon_id': '573',\n",
       " 'num_runs_in_accession': 1,\n",
       " 'organization_address': 'Infectious Diseases, MD Anderson Cancer Center, 1515 Holcombe Blvd, Houston, TX, United States of America',\n",
       " 'organization_contacts': ['Samuel Shelburne, sshelburne@mdanderson.org'],\n",
       " 'organization_name': 'MD Anderson Cancer Center',\n",
       " 'project_id': 'SRP108482',\n",
       " 'read_quality_counts': [{'10': 1300790,\n",
       "   '11': 1470512,\n",
       "   '12': 68915,\n",
       "   '13': 110975,\n",
       "   '14': 365718,\n",
       "   '15': 406920,\n",
       "   '16': 337555,\n",
       "   '17': 422269,\n",
       "   '18': 484016,\n",
       "   '19': 347508,\n",
       "   '2': 54440,\n",
       "   '20': 1060628,\n",
       "   '21': 604236,\n",
       "   '22': 1516360,\n",
       "   '23': 1245561,\n",
       "   '24': 1147560,\n",
       "   '25': 1719114,\n",
       "   '26': 497277,\n",
       "   '27': 1571301,\n",
       "   '28': 774746,\n",
       "   '29': 1119963,\n",
       "   '30': 910363,\n",
       "   '31': 1713524,\n",
       "   '32': 730580,\n",
       "   '33': 795846,\n",
       "   '34': 9291344,\n",
       "   '35': 3061644,\n",
       "   '36': 5841820,\n",
       "   '37': 12588357,\n",
       "   '38': 70194976,\n",
       "   '7': 68578,\n",
       "   '8': 781278,\n",
       "   '9': 2333765}],\n",
       " 'read_quality_counts_maxrun': {'10': 1300790,\n",
       "  '11': 1470512,\n",
       "  '12': 68915,\n",
       "  '13': 110975,\n",
       "  '14': 365718,\n",
       "  '15': 406920,\n",
       "  '16': 337555,\n",
       "  '17': 422269,\n",
       "  '18': 484016,\n",
       "  '19': 347508,\n",
       "  '2': 54440,\n",
       "  '20': 1060628,\n",
       "  '21': 604236,\n",
       "  '22': 1516360,\n",
       "  '23': 1245561,\n",
       "  '24': 1147560,\n",
       "  '25': 1719114,\n",
       "  '26': 497277,\n",
       "  '27': 1571301,\n",
       "  '28': 774746,\n",
       "  '29': 1119963,\n",
       "  '30': 910363,\n",
       "  '31': 1713524,\n",
       "  '32': 730580,\n",
       "  '33': 795846,\n",
       "  '34': 9291344,\n",
       "  '35': 3061644,\n",
       "  '36': 5841820,\n",
       "  '37': 12588357,\n",
       "  '38': 70194976,\n",
       "  '7': 68578,\n",
       "  '8': 781278,\n",
       "  '9': 2333765},\n",
       " 'run_ids': ['SRR5642053'],\n",
       " 'run_ids_maxrun': 'SRR5642053',\n",
       " 'sample_id': 'SRS2248214',\n",
       " 'sequencing_method': 'illumina',\n",
       " 'study_abstract': 'This project sought to determine whether whole genome sequencing could accurately predict antimicrobial resistance to commonly used antibiotics in the treatment of bacteria causing infections in patients with compromised immune systems.',\n",
       " 'study_id': 'SRP108482',\n",
       " 'study_links': {'pubmed': '28472260'},\n",
       " 'study_title': 'This deposit is composed of paired-end reads from 90 isolates of four different gram-negative bacterial species. The raw reads were used to generate predictions of antimicrobial resistance. Raw sequence reads',\n",
       " 'study_type': 'Other',\n",
       " 'submission_id': 'SRA569671',\n",
       " 'taxon_scientific_name': 'Klebsiella pneumoniae',\n",
       " 'total_num_bases': [124938439],\n",
       " 'total_num_bases_maxrun': 124938439,\n",
       " 'total_num_reads': [256943],\n",
       " 'total_num_reads_maxrun': 256943}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdict.keys()[0:5]\n",
    "sdict['4123344']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element EXPERIMENT_PACKAGE at 0x1045f5cb0>,\n",
       " <Element EXPERIMENT_PACKAGE at 0x1038a1878>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sra_xml.getchildren()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element EXPERIMENT_PACKAGE at 0x1045f5cb0>,\n",
       " <Element EXPERIMENT_PACKAGE at 0x1038a1878>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sra_samples = sra_xml.findall(\"EXPERIMENT_PACKAGE\")\n",
    "sdict = {}\n",
    "sra_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element EXPERIMENT_PACKAGE at 0x1045f5cb0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sra_sample = sra_samples[0]\n",
    "sra_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element EXPERIMENT at 0x103647cf8>,\n",
       " <Element SUBMISSION at 0x103789518>,\n",
       " <Element Organization at 0x103789248>,\n",
       " <Element STUDY at 0x10332d5a8>,\n",
       " <Element SAMPLE at 0x10332d908>,\n",
       " <Element Pool at 0x10332d488>,\n",
       " <Element RUN_SET at 0x10332da70>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sra_sample.getchildren()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rkd mutant ovules late phase A\n"
     ]
    }
   ],
   "source": [
    "if sra_sample.find(\"SAMPLE\").findtext(\"DESCRIPTION\") is not None: \n",
    "    print sra_sample.find(\"SAMPLE\").findtext(\"DESCRIPTION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 3.B - elink to BioSample, Pubmed, Nuccore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#asking for a friend - how many of the sra uids have elinks to biosample?\n",
    "elink_url = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=sra&db=biosample&tool=metaseq&email=metaseekcloud%40gmail.com'\n",
    "\n",
    "for key in batch_uid_list:\n",
    "    #this makes url with end &id=###&id=###&id=### - returns a set of links in order of sra uids\n",
    "    elink_url = elink_url+'&id='+str(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elink_url = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=sra&db=biosample&tool=metaseq&email=metaseekcloud%40gmail.com'\n",
    "for batch in batches:\n",
    "    print \"processing batch %s\" % batch\n",
    "    batch_uid_list = map(int,uid_list[batch[0]:batch[1]])\n",
    "\n",
    "    for key in batch_uid_list:\n",
    "        elink_url = elink_url+'&id='+str(key)\n",
    "    try:\n",
    "\n",
    "        e = urllib.urlopen(elink_url)\n",
    "        link_tree = etree.parse(e)\n",
    "        e.close()\n",
    "        link_xml = link_tree.getroot()\n",
    "        print link_xml\n",
    "    except etree.XMLSyntaxError, detail:\n",
    "        print detail.error_log\n",
    "\n",
    "    #note if there's no biosample link, <LinkSetDb> with <DbTo>=='biosample' just won't exist\n",
    "    biosample_ids = []\n",
    "    pubmed_ids = []\n",
    "    linksets = link_xml.findall(\"LinkSet\")\n",
    "    for link in linksets:\n",
    "        linkdb = link.findall(\"LinkSetDb\")\n",
    "        if len(linkdb)>0:\n",
    "            for db in linkdb:\n",
    "                if db.findtext(\"DbTo\")=='biosample':\n",
    "                    biosample_ids.append(int(db.find(\"Link\").findtext(\"Id\")))\n",
    "                if db.findtext(\"DbTo\")=='pubmed':\n",
    "                    pubmed_ids.append(int(db.find(\"Link\").findtext(\"Id\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'urllib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ff1bbb7f5c6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melink_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlink_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0metree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'urllib' is not defined"
     ]
    }
   ],
   "source": [
    "e = urllib.urlopen(elink_url)\n",
    "link_tree = etree.parse(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#takes list of SRX UIDs to query (batch_uid_list), and sdict into which to insert link uids; \n",
    "#return sdict with 'biosample_uid', 'pubmed_uids', and/or 'nuccore_uids' inserted; and link dict with lists of biosample_uids, pubmed_uids, and nuccore_uids to scrape\n",
    "def get_links(batch_uid_list, sdict):\n",
    "    print \"sending elink request and parsing XML...\"\n",
    "    elink_url = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=sra&db=biosample,pubmed,nuccore&tool=metaseq&email=metaseekcloud%40gmail.com'\n",
    "    for key in batch_uid_list:\n",
    "        #this makes url with end &id=###&id=###&id=### - returns a set of links in order of sra uids\n",
    "        elink_url = elink_url+'&id='+str(key)\n",
    "    #run api request and parse xml\n",
    "    e = urllib.urlopen(elink_url)\n",
    "    link_tree = etree.parse(e)\n",
    "    e.close()\n",
    "    link_xml = link_tree.getroot()\n",
    "    print \"...parsing done!\"\n",
    "\n",
    "    print \"finding links...\"\n",
    "    #scrape elink info\n",
    "    #note if there's no biosample link, <LinkSetDb> with <DbTo>=='biosample' just won't exist\n",
    "    biosample_uids = []\n",
    "    pubmed_uids = []\n",
    "    nuccore_uids = []\n",
    "\n",
    "    linksets = link_xml.findall(\"LinkSet\")\n",
    "    for linkset in linksets:\n",
    "        srx_uid = linkset.find(\"IdList\").findtext(\"Id\")\n",
    "        #links from each target db will be in a tab called \"LinkSetDb\"\n",
    "        if len(linkset.findall(\"LinkSetDb\"))>0:\n",
    "            for link in linkset.findall(\"LinkSetDb\"):\n",
    "                id_set = []\n",
    "                if link.findtext(\"DbTo\")=='biosample':\n",
    "                    #for all Links, get Ids\n",
    "                    for uid in link.findall(\"Link\"):\n",
    "                        id_set.append(int(uid.findtext(\"Id\")))\n",
    "                    biosample_uids.extend(id_set)\n",
    "                    sdict[srx_uid]['biosample_uid'] = id_set\n",
    "                elif link.findtext(\"DbTo\")=='pubmed':\n",
    "                    for uid in link.findall(\"Link\"):\n",
    "                        id_set.append(int(uid.findtext(\"Id\")))\n",
    "                    pubmed_uids.extend(id_set)\n",
    "                    sdict[srx_uid]['pubmed_uids'] = id_set\n",
    "                elif link.findtext(\"DbTo\")=='nuccore':\n",
    "                    for uid in link.findall(\"Link\"):\n",
    "                        id_set.append(int(uid.findtext(\"Id\")))\n",
    "                    nuccore_uids.extend(id_set)\n",
    "                    sdict[srx_uid]['nuccore_uids'] = id_set\n",
    "\n",
    "    biosample_uids = list(set(biosample_uids))\n",
    "    pubmed_uids = list(set(pubmed_uids))\n",
    "    nuccore_uids = list(set(nuccore_uids))\n",
    "    \n",
    "    linkdict = {'biosample_uids':biosample_uids,'pubmed_uids':pubmed_uids,'nuccore_uids':nuccore_uids}\n",
    "    print \"number of biosamples to scrape: %s\" % len(linkdict['biosample_uids'])\n",
    "    print \"number of pubmeds to scrape: %s\" % len(linkdict['pubmed_uids'])\n",
    "    print \"number of nuccores to scrape: %s\" % len(linkdict['nuccore_uids'])\n",
    "    \n",
    "    return sdict,linkdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380 [7151616, 7184736, 5570637, 7176304, 7176307, 7176308, 7176309, 7176310, 7176311, 7176313]\n",
      "7 [28472260, 26044422, 27365352, 25103754, 25013133, 26679598, 25540336]\n",
      "44 [1123333122, 651352708, 1028628997, 763503881, 763528202, 1194697611, 1003446637, 1003442578, 1003436440, 1003458205]\n"
     ]
    }
   ],
   "source": [
    "biosample_uids = []\n",
    "pubmed_uids = []\n",
    "nuccore_uids = []\n",
    "\n",
    "linksets = link_xml.findall(\"LinkSet\")\n",
    "for linkset in linksets:\n",
    "    #srx uid\n",
    "    srx_uid = linkset.find(\"IdList\").findtext(\"Id\")\n",
    "    #links from each target db will be in a tab called \"LinkSetDb\"\n",
    "    if len(linkset.findall(\"LinkSetDb\"))>0:\n",
    "        for link in linkset.findall(\"LinkSetDb\"):\n",
    "            id_set = []\n",
    "            if link.findtext(\"DbTo\")=='biosample':\n",
    "                #for all Links, get Ids\n",
    "                for uid in link.findall(\"Link\"):\n",
    "                    id_set.append(int(uid.findtext(\"Id\")))\n",
    "                biosample_uids.extend(id_set)\n",
    "                #sdict[srx_uid]['biosample_uid'] = id_set\n",
    "            elif link.findtext(\"DbTo\")=='pubmed':\n",
    "                for uid in link.findall(\"Link\"):\n",
    "                    id_set.append(int(uid.findtext(\"Id\")))\n",
    "                pubmed_uids.extend(id_set)\n",
    "                #sdict[srx_uid]['pubmed_uids'] = id_set\n",
    "            elif link.findtext(\"DbTo\")=='nuccore':\n",
    "                for uid in link.findall(\"Link\"):\n",
    "                    id_set.append(int(uid.findtext(\"Id\")))\n",
    "                nuccore_uids.extend(id_set)\n",
    "                #sdict[srx_uid]['nuccore_uids'] = id_set\n",
    "\n",
    "biosample_uids = list(set(biosample_uids))\n",
    "pubmed_uids = list(set(pubmed_uids))\n",
    "nuccore_uids = list(set(nuccore_uids))\n",
    "\n",
    "print len(biosample_uids), biosample_uids[0:10]\n",
    "print len(pubmed_uids), pubmed_uids[0:10]\n",
    "print len(nuccore_uids), nuccore_uids[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sending elink request and parsing XML...\n",
      "...parsing done!\n",
      "finding links...\n",
      "number of biosamples to scrape: 380\n",
      "number of pubmeds to scrape: 7\n",
      "number of nuccores to scrape: 44\n"
     ]
    }
   ],
   "source": [
    "sdict, linkdict = get_links(batch_uid_list=batch_uid_list,sdict=sdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pubmed_uids', 'nuccore_uids', 'biosample_uids']\n",
      "7\n",
      "44\n",
      "380\n",
      "166 99 445\n"
     ]
    }
   ],
   "source": [
    "print linkdict.keys()\n",
    "print len(linkdict['pubmed_uids'])\n",
    "print len(linkdict['nuccore_uids'])\n",
    "print len(linkdict['biosample_uids'])\n",
    "pubmeds = []\n",
    "nuccores = []\n",
    "biosamples = []\n",
    "for key in sdict.keys():\n",
    "    if 'pubmed_uids' in sdict[key].keys():\n",
    "        pubmeds.append(key)\n",
    "    if 'nuccore_uids' in sdict[key].keys():\n",
    "        nuccores.append(key)\n",
    "    if 'biosample_uid' in sdict[key].keys():\n",
    "        biosamples.append(key)\n",
    "print len(pubmeds),len(nuccores),len(biosamples)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 12, 'that': 'for'} {'this': 24, 'those': 'next'}\n",
      "{'this': 24, 'those': 'next', 'that': 'for'} {'this': 24, 'those': 'next'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "d3 = {'this':12,'that':'for'}\n",
    "d4 = {'this':24,'those':'next'}\n",
    "print d3, d4\n",
    "#when run dict1.update(dict2), dict2 is added to dict1. If there's overlap in the keys, dict2 val replaces dict1\n",
    "d3.update(d4)\n",
    "print d3, d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "not in\n"
     ]
    }
   ],
   "source": [
    "if d3['this']==24:\n",
    "    print \"yes\"\n",
    "if 'wait' in d3.keys():\n",
    "    print \"in\"\n",
    "else:\n",
    "    print \"not in\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old = [2,4,6]\n",
    "new = [7,8,9]\n",
    "old+new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old.extend(new)\n",
    "old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
