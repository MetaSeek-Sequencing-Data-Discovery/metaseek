{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto ingestion of SRA metadata\n",
    "\n",
    "1. Get a list of SRA UIDs to scrape\n",
    "    1. get all publically accessible SRA (SRX) accessions\n",
    "    2. remove SRA UIDs already been ingested into MetaSeek DB (all 'source_db_uid' where 'source_db' = 'SRA'\n",
    "    \n",
    "2. Split UIDs to scrape into batches of 500\n",
    "\n",
    "3. For each batch, scrape metadata:\n",
    "    1. efetch scrape SRA\n",
    "    2. elink to BioSample, Pubmed, Nuccore\n",
    "    3. efetch scrape BioSample, if exists\n",
    "    4. efetch scrape Pubmed, if exists\n",
    "    5. efetch scrape nuccore, if exists\n",
    "    \n",
    "4. Merge redundant cols to MIxS-compliant MetaSeek fields (separate script)\n",
    "\n",
    "5. Parse fields with controlled vocabularies to MIxS CV, if possible (NOTE: future error parsing)\n",
    "\n",
    "6. Insert scraped data into MetaSeek DB directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.A - Get a list of SRA UIDs to scrape\n",
    "\n",
    "* find out how many publicly available samples there are; make list retstarts to use \n",
    "* Call esearch api, with rotating retstarts, to get full UID list\n",
    "\n",
    "NOTE - most comprehensive API call to find ALL the SRA samples I can find (since an empty search term returns no accessions, not all) is term=public&field=ACS; returns all publically accessible SRA UIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_retstart_list(url):\n",
    "    #define retstarts need for get_uid_list eutilities requests - since can only get 100,000 at a time, need to make multiple queries to get total list\n",
    "    #find out count of UIDs going to pull from SRA\n",
    "    g = urllib.urlopen(url)\n",
    "    count_tree = etree.parse(g)\n",
    "    g.close()\n",
    "    count_xml = count_tree.getroot()\n",
    "    num_uids = count_xml.findtext(\"Count\")\n",
    "    print 'number of publicly available UIDs in SRA: %s' % num_uids\n",
    "    num_queries = 1+int(num_uids)/100000  #number of queries to do, with shifting retstart\n",
    "    retstart_list = [i*100000 for i in range(num_queries)]\n",
    "    print 'retstarts to use: %s' % retstart_list\n",
    "    return retstart_list\n",
    "\n",
    "def get_uid_list(ret_list):\n",
    "    #scrape UIDs into list\n",
    "    uid_list = []\n",
    "    for retstart in ret_list:\n",
    "        f = urllib.urlopen('https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=sra&term=public&field=ACS&tool=metaseq&email=metaseekcloud%40gmail.com&retmax=100000&retstart='+str(retstart))\n",
    "        uid_tree = etree.parse(f)\n",
    "        f.close()\n",
    "        uid_xml = uid_tree.getroot()\n",
    "        print \"appending %s accessions\" % len(uid_xml.find(\"IdList\").findall(\"Id\"))\n",
    "        #add uids to list of accessions\n",
    "        for id in uid_xml.find(\"IdList\").iterchildren():\n",
    "            value = id.text\n",
    "            uid_list.append(value)\n",
    "    return uid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of publicly available UIDs in SRA: 2694787\n",
      "retstarts to use: [0, 100000, 200000, 300000, 400000, 500000, 600000, 700000, 800000, 900000, 1000000, 1100000, 1200000, 1300000, 1400000, 1500000, 1600000, 1700000, 1800000, 1900000, 2000000, 2100000, 2200000, 2300000, 2400000, 2500000, 2600000]\n"
     ]
    }
   ],
   "source": [
    "retstart_list = get_retstart_list(url='https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=sra&term=public&field=ACS&rettype=count&tool=metaseq&email=metaseekcloud%40gmail.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 100000 accessions\n",
      "appending 94787 accessions\n"
     ]
    }
   ],
   "source": [
    "uid_list = get_uid_list(ret_list=retstart_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO 1.B - Remove SRA UIDs already in in MetaSeek DB\n",
    "\n",
    "db_source_uid where db_source = 'SRA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Split UIDs to scrape into batches of 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_batches(uid_list):\n",
    "    starts = range(0,len(uid_list),500)\n",
    "    ends = range(500,len(uid_list),500)\n",
    "    ends.append(len(uid_list))\n",
    "    batches = [list(a) for a in zip(starts, ends)]\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches = get_batches(uid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5390\n",
      "[[0, 500], [500, 1000], [1000, 1500], [1500, 2000], [2000, 2500], [2500, 3000], [3000, 3500], [3500, 4000], [4000, 4500], [4500, 5000]]\n",
      "[[2690000, 2690500], [2690500, 2691000], [2691000, 2691500], [2691500, 2692000], [2692000, 2692500], [2692500, 2693000], [2693000, 2693500], [2693500, 2694000], [2694000, 2694500], [2694500, 2694787]]\n"
     ]
    }
   ],
   "source": [
    "print len(batches)\n",
    "print batches[0:10]\n",
    "print batches[-10:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.A - Efetch scrape SRA metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_srx_metadata(batch_uid_list):\n",
    "    srx_url = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=sra&tool=metaseq&email=metaseekcloud%40gmail.com&id='+str(batch_uid_list)[1:-1]\n",
    "    s = urllib.urlopen(srx_url)\n",
    "    sra_tree = etree.parse(s)\n",
    "    s.close()\n",
    "    sra_xml = sra_tree.getroot()\n",
    "\n",
    "    sra_samples = sra_xml.findall(\"EXPERIMENT_PACKAGE\")\n",
    "    sdict = {}\n",
    "\n",
    "    for which,sra_sample in enumerate(sra_samples): #the order of experiment_packages ARE in order of sra ids given - that's good\n",
    "        srx_dict = {}\n",
    "\n",
    "        sdict_id = str(batch_uid_list[which])\n",
    "        srx_dict['db_source_uid'] = sdict_id\n",
    "        srx_dict['db_source'] = 'SRA'\n",
    "        srx_dict['expt_link'] = \"https://www.ncbi.nlm.nih.gov/sra/\"+str(sdict_id)\n",
    "\n",
    "        #There are 7 top tag groups. Have to scrape data a little different for each: ['EXPERIMENT','SUBMISSION','Organization','STUDY','SAMPLE','Pool','RUN_SET']\n",
    "\n",
    "        ###EXPERIMENT -\n",
    "        if sra_sample.find(\"EXPERIMENT\").find(\"IDENTIFIERS\").findtext(\"PRIMARY_ID\") is not None:\n",
    "            srx_dict['expt_id'] = sra_sample.find(\"EXPERIMENT\").find(\"IDENTIFIERS\").findtext(\"PRIMARY_ID\")\n",
    "        if sra_sample.find(\"EXPERIMENT\").findtext(\"TITLE\") is not None:\n",
    "            srx_dict['expt_title'] = sra_sample.find(\"EXPERIMENT\").findtext(\"TITLE\")\n",
    "        if sra_sample.find(\"EXPERIMENT\").find(\"STUDY_REF\").find(\"IDENTIFIERS\") is not None:\n",
    "            if sra_sample.find(\"EXPERIMENT\").find(\"STUDY_REF\").find(\"IDENTIFIERS\").findtext(\"PRIMARY_ID\") is not None:\n",
    "                srx_dict[\"project_id\"] = sra_sample.find(\"EXPERIMENT\").find(\"STUDY_REF\").find(\"IDENTIFIERS\").findtext(\"PRIMARY_ID\")   \n",
    "        if sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").findtext(\"DESIGN_DESCRIPTION\") is not None:\n",
    "            srx_dict['expt_design_description'] = sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").findtext(\"DESIGN_DESCRIPTION\")\n",
    "        if sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").find(\"SAMPLE_DESCRIPTOR\").find(\"IDENTIFIERS\").findtext(\"PRIMARY_ID\") is not None:\n",
    "            srx_dict['sample_id'] = sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").find(\"SAMPLE_DESCRIPTOR\").find(\"IDENTIFIERS\").findtext(\"PRIMARY_ID\")\n",
    "        if sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").find(\"LIBRARY_DESCRIPTOR\").findtext(\"LIBRARY_NAME\") is not None:\n",
    "            srx_dict['library_name'] = sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").find(\"LIBRARY_DESCRIPTOR\").findtext(\"LIBRARY_NAME\")\n",
    "        if sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").find(\"LIBRARY_DESCRIPTOR\").findtext(\"LIBRARY_STRATEGY\") is not None:\n",
    "            srx_dict['library_strategy'] = sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").find(\"LIBRARY_DESCRIPTOR\").findtext(\"LIBRARY_STRATEGY\")\n",
    "        if sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").find(\"LIBRARY_DESCRIPTOR\").findtext(\"LIBRARY_SOURCE\").lower() is not None:\n",
    "            srx_dict['library_source'] = sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").find(\"LIBRARY_DESCRIPTOR\").findtext(\"LIBRARY_SOURCE\").lower()\n",
    "        ###change library_selection to MIxS field library_screening_strategy (cv for SRA, not for MIxS)\n",
    "        if sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").find(\"LIBRARY_DESCRIPTOR\").findtext(\"LIBRARY_SELECTION\") is not None:\n",
    "            srx_dict['library_screening_strategy'] = sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").find(\"LIBRARY_DESCRIPTOR\").findtext(\"LIBRARY_SELECTION\")\n",
    "        ###change library_layout to MIxS field library_construction_method - cv single | paired\n",
    "        if sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").find(\"LIBRARY_DESCRIPTOR\").findtext(\"LIBRARY_LAYOUT\") is not None:\n",
    "            srx_dict['library_construction_method'] = sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").find(\"LIBRARY_DESCRIPTOR\").find(\"LIBRARY_LAYOUT\").getchildren()[0].tag.lower()\n",
    "        if sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").find(\"LIBRARY_DESCRIPTOR\").findtext(\"LIBRARY_CONSTRUCTION_PROTOCOL\") is not None:\n",
    "            srx_dict['library_construction_protocol'] = sra_sample.find(\"EXPERIMENT\").find(\"DESIGN\").find(\"LIBRARY_DESCRIPTOR\").findtext(\"LIBRARY_CONSTRUCTION_PROTOCOL\")\n",
    "        ###change platform to MIxS field sequencing_method - cv in SRA (not in MIxS)\n",
    "        if sra_sample.find(\"EXPERIMENT\").find(\"PLATFORM\").getchildren() is not None:\n",
    "            srx_dict['sequencing_method'] = sra_sample.find(\"EXPERIMENT\").find(\"PLATFORM\").getchildren()[0].tag.lower()\n",
    "            if sra_sample.find(\"EXPERIMENT\").find(\"PLATFORM\").getchildren()[0].findtext(\"INSTRUMENT_MODEL\") is not None:\n",
    "                srx_dict['instrument_model'] = sra_sample.find(\"EXPERIMENT\").find(\"PLATFORM\").getchildren()[0].findtext(\"INSTRUMENT_MODEL\")\n",
    "        \n",
    "        ###SUBMISSION - just need the submission id\n",
    "        if sra_sample.find(\"SUBMISSION\").find(\"IDENTIFIERS\").findtext(\"PRIMARY_ID\") is not None:\n",
    "            srx_dict['submission_id'] = sra_sample.find(\"SUBMISSION\").find(\"IDENTIFIERS\").findtext(\"PRIMARY_ID\")\n",
    "\n",
    "        ###Organization - name, address, and contact\n",
    "        if sra_sample.find(\"Organization\").findtext(\"Name\") is not None:\n",
    "            srx_dict['organization_name'] = sra_sample.find(\"Organization\").findtext(\"Name\")\n",
    "        if sra_sample.find(\"Organization\").find(\"Address\") is not None:\n",
    "            address = ''\n",
    "            for line in sra_sample.find(\"Organization\").find(\"Address\").iterchildren():\n",
    "                address = address+line.text+', '\n",
    "            address = address[:-2]\n",
    "            srx_dict['organization_address'] = address\n",
    "        if len(sra_sample.find(\"Organization\").findall(\"Contact\"))>0:\n",
    "            contacts = []\n",
    "            for contact in sra_sample.find(\"Organization\").findall(\"Contact\"):\n",
    "                name = contact.find(\"Name\").find(\"First\").text+' '+contact.find(\"Name\").find(\"Last\").text\n",
    "                email = contact.get('email')\n",
    "                contacts.append(name+', '+email)\n",
    "            srx_dict['organization_contacts'] = contacts\n",
    "        \n",
    "        ###STUDY -\n",
    "        if sra_sample.find(\"STUDY\").find(\"IDENTIFIERS\").findtext(\"PRIMARY_ID\") is not None: \n",
    "            srx_dict['study_id'] = sra_sample.find(\"STUDY\").find(\"IDENTIFIERS\").findtext(\"PRIMARY_ID\")\n",
    "        if sra_sample.find(\"STUDY\").find(\"DESCRIPTOR\").findtext(\"STUDY_TITLE\") is not None:\n",
    "            srx_dict['study_title'] = sra_sample.find(\"STUDY\").find(\"DESCRIPTOR\").findtext(\"STUDY_TITLE\")\n",
    "        ###rename existing_study_type to study_type\n",
    "        if sra_sample.find(\"STUDY\").find(\"DESCRIPTOR\").find(\"STUDY_TYPE\") is not None:\n",
    "            if sra_sample.find(\"STUDY\").find(\"DESCRIPTOR\").find(\"STUDY_TYPE\").get(\"existing_study_type\")==\"Other\":\n",
    "                srx_dict['study_type'] = 'Other'\n",
    "                if sra_sample.find(\"STUDY\").find(\"DESCRIPTOR\").find(\"STUDY_TYPE\").get(\"add_study_type\") is not None:\n",
    "                    srx_dict['study_type_other'] = sra_sample.find(\"STUDY\").find(\"DESCRIPTOR\").find(\"STUDY_TYPE\").get(\"add_study_type\")\n",
    "            else:\n",
    "                srx_dict['study_type'] = sra_sample.find(\"STUDY\").find(\"DESCRIPTOR\").find(\"STUDY_TYPE\").get(\"existing_study_type\")\n",
    "        if sra_sample.find(\"STUDY\").find(\"DESCRIPTOR\").findtext(\"STUDY_ABSTRACT\"):\n",
    "            srx_dict['study_abstract'] = sra_sample.find(\"STUDY\").find(\"DESCRIPTOR\").findtext(\"STUDY_ABSTRACT\")\n",
    "        if len(sra_sample.find(\"STUDY\").find(\"STUDY_LINKS\").getchildren())>0:\n",
    "            study_links = {}\n",
    "            for study_link in sra_sample.find(\"STUDY\").find(\"STUDY_LINKS\").iterchildren():\n",
    "                if study_link.find(\"XREF_LINK\") is not None:\n",
    "                    study_links[study_link.find(\"XREF_LINK\").findtext(\"DB\")] = study_link.find(\"XREF_LINK\").findtext(\"ID\")\n",
    "                if study_link.find(\"URL_LINK\") is not None:\n",
    "                    study_links[study_link.find(\"URL_LINK\").findtext(\"LABEL\")] = study_link.find(\"URL_LINK\").findtext(\"URL\")\n",
    "            srx_dict['study_links'] = study_links\n",
    "        if len(sra_sample.find(\"STUDY\").find(\"STUDY_ATTRIBUTES\").getchildren())>0:\n",
    "            study_attributes = {}\n",
    "            for attr in sra_sample.find(\"STUDY\").find(\"STUDY_ATTRIBUTES\").iterchildren():\n",
    "                study_attributes[attr.findtext(\"TAG\")] = attr.findtext(\"VALUE\")\n",
    "            srx_dict['study_attributes'] = study_attributes\n",
    "\n",
    "        ###SAMPLE - just need sample id\n",
    "        if sra_sample.find(\"SAMPLE\").find(\"IDENTIFIERS\").findtext(\"PRIMARY_ID\") is not None:\n",
    "            srx_dict['sample_id'] = sra_sample.find(\"SAMPLE\").find(\"IDENTIFIERS\").findtext(\"PRIMARY_ID\")\n",
    "\n",
    "        ###Pool - skip, redundant\n",
    "\n",
    "        ###RUN_SET - record stats for each run as list, for best run (maxrun, run for which total_num_reads is largest) as single value\n",
    "        run_ids = []\n",
    "        total_num_reads = []\n",
    "        total_num_bases = []\n",
    "        download_size = []\n",
    "        avg_read_length = []\n",
    "        baseA_count = []\n",
    "        baseC_count = []\n",
    "        baseG_count = []\n",
    "        baseT_count = []\n",
    "        baseN_count = []\n",
    "        gc_percent = []\n",
    "        read_quality_counts = []\n",
    "\n",
    "        if len(sra_sample.find(\"RUN_SET\").findall(\"RUN\"))>0:\n",
    "            srx_dict['num_runs_in_accession'] = len(sra_sample.find(\"RUN_SET\").findall(\"RUN\"))\n",
    "            for run in sra_sample.find(\"RUN_SET\").findall(\"RUN\"):\n",
    "                run_ids.append(run.get(\"accession\"))\n",
    "                total_num_reads.append(int(run.get(\"total_spots\")))\n",
    "                total_num_bases.append(int(run.get(\"total_bases\")))\n",
    "                download_size.append(int(run.get(\"size\")))\n",
    "                avg_read_length.append(float(run.get(\"total_bases\"))/(float(run.find(\"Run\").get(\"spot_count\"))+float(run.find(\"Run\").get(\"spot_count_mates\"))))\n",
    "                for base in run.find(\"Bases\").findall(\"Base\"):\n",
    "                    if base.get(\"value\")==\"A\":\n",
    "                        baseA_count.append(int(base.get(\"count\")))\n",
    "                        countA = int(base.get(\"count\"))\n",
    "                    if base.get(\"value\")==\"C\":\n",
    "                        baseC_count.append(int(base.get(\"count\")))\n",
    "                        countC = int(base.get(\"count\"))\n",
    "                    if base.get(\"value\")==\"G\":\n",
    "                        baseG_count.append(int(base.get(\"count\")))\n",
    "                        countG = int(base.get(\"count\"))\n",
    "                    if base.get(\"value\")==\"T\":\n",
    "                        baseT_count.append(int(base.get(\"count\")))\n",
    "                        countT = int(base.get(\"count\"))\n",
    "                    if base.get(\"value\")==\"N\":\n",
    "                        baseN_count.append(int(base.get(\"count\")))\n",
    "                        countN = int(base.get(\"count\"))\n",
    "                gc_percent.append(float(countG+countC)/float(countC+countG+countA+countT))\n",
    "                qual_count = {}\n",
    "                if run.find(\"Run\").find(\"QualityCount\") is not None:\n",
    "                    for qual in run.find(\"Run\").find(\"QualityCount\").findall(\"Quality\"):\n",
    "                        qual_count[qual.get(\"value\")] = int(qual.get(\"count\"))\n",
    "                read_quality_counts.append(qual_count)\n",
    "\n",
    "\n",
    "            max_index = total_num_reads.index(max(total_num_reads))\n",
    "\n",
    "            srx_dict['run_ids'] = run_ids\n",
    "            srx_dict['run_ids_maxrun'] = run_ids[max_index]\n",
    "            srx_dict['total_num_reads'] = total_num_reads\n",
    "            srx_dict['total_num_reads_maxrun'] = total_num_reads[max_index]\n",
    "            srx_dict['total_num_bases'] = total_num_bases\n",
    "            srx_dict['total_num_bases_maxrun'] = total_num_bases[max_index]\n",
    "            srx_dict['download_size'] = download_size\n",
    "            srx_dict['download_size_maxrun'] = download_size[max_index]\n",
    "            srx_dict['avg_read_length'] = avg_read_length\n",
    "            srx_dict['avg_read_length_maxrun'] = avg_read_length[max_index]\n",
    "            srx_dict['baseA_count'] = baseA_count\n",
    "            srx_dict['baseA_count_maxrun'] = baseA_count[max_index]\n",
    "            srx_dict['baseC_count'] = baseC_count\n",
    "            srx_dict['baseC_count_maxrun'] = baseC_count[max_index]\n",
    "            srx_dict['baseG_count'] = baseG_count\n",
    "            srx_dict['baseG_count_maxrun'] = baseG_count[max_index]\n",
    "            srx_dict['baseT_count'] = baseT_count\n",
    "            srx_dict['baseT_count_maxrun'] = baseT_count[max_index]\n",
    "            srx_dict['baseN_count'] = baseN_count\n",
    "            srx_dict['baseN_count_maxrun'] = baseN_count[max_index]\n",
    "            srx_dict['gc_percent'] = gc_percent\n",
    "            srx_dict['gc_percent_maxrun'] = gc_percent[max_index]\n",
    "            srx_dict['read_quality_counts'] = read_quality_counts\n",
    "            srx_dict['read_quality_counts_maxrun'] = read_quality_counts[max_index]\n",
    "\n",
    "\n",
    "        sdict[sdict_id] = srx_dict\n",
    "\n",
    "    return sdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4124571,\n",
       " 4124570,\n",
       " 4124569,\n",
       " 4124568,\n",
       " 4124567,\n",
       " 4124566,\n",
       " 4124565,\n",
       " 4124564,\n",
       " 4124563,\n",
       " 4124562]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = batches[0]\n",
    "batch_uid_list = map(int,uid_list[batch[0]:batch[1]])\n",
    "batch_uid_list[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=sra&tool=metaseq&email=metaseekcloud%40gmail.com&id=4124571, 4124570'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srx_url = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=sra&tool=metaseq&email=metaseekcloud%40gmail.com&id='+str(batch_uid_list)[1:-1][0:16] \n",
    "srx_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = urllib.urlopen(srx_url)\n",
    "sra_tree = etree.parse(s)\n",
    "s.close()\n",
    "sra_xml = sra_tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element EXPERIMENT_PACKAGE at 0x1045f5cb0>,\n",
       " <Element EXPERIMENT_PACKAGE at 0x1038a1878>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sra_xml.getchildren()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element EXPERIMENT_PACKAGE at 0x1045f5cb0>,\n",
       " <Element EXPERIMENT_PACKAGE at 0x1038a1878>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sra_samples = sra_xml.findall(\"EXPERIMENT_PACKAGE\")\n",
    "sdict = {}\n",
    "sra_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element EXPERIMENT_PACKAGE at 0x1045f5cb0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sra_sample = sra_samples[0]\n",
    "sra_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element EXPERIMENT at 0x103647cf8>,\n",
       " <Element SUBMISSION at 0x103789518>,\n",
       " <Element Organization at 0x103789248>,\n",
       " <Element STUDY at 0x10332d5a8>,\n",
       " <Element SAMPLE at 0x10332d908>,\n",
       " <Element Pool at 0x10332d488>,\n",
       " <Element RUN_SET at 0x10332da70>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sra_sample.getchildren()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element RUN at 0x1037899e0>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sra_sample.find(\"RUN_SET\").findall(\"RUN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_ids = []\n",
    "total_num_reads = []\n",
    "total_num_bases = []\n",
    "download_size = []\n",
    "avg_read_length = []\n",
    "baseA_count = []\n",
    "baseC_count = []\n",
    "baseG_count = []\n",
    "baseT_count = []\n",
    "baseN_count = []\n",
    "gc_percent = []\n",
    "read_quality_counts = []\n",
    "\n",
    "num_runs_in_accession = len(sra_sample.find(\"RUN_SET\").findall(\"RUN\"))\n",
    "for run in sra_sample.find(\"RUN_SET\").findall(\"RUN\"):\n",
    "    run_ids.append(run.get(\"accession\"))\n",
    "    total_num_reads.append(int(run.get(\"total_spots\")))\n",
    "    total_num_bases.append(int(run.get(\"total_bases\")))\n",
    "    download_size.append(int(run.get(\"size\")))\n",
    "    avg_read_length.append(float(run.get(\"total_bases\"))/(float(run.find(\"Run\").get(\"spot_count\"))+float(run.find(\"Run\").get(\"spot_count_mates\"))))\n",
    "    for base in run.find(\"Bases\").findall(\"Base\"):\n",
    "        if base.get(\"value\")==\"A\":\n",
    "            baseA_count.append(int(base.get(\"count\")))\n",
    "            countA = int(base.get(\"count\"))\n",
    "        if base.get(\"value\")==\"C\":\n",
    "            baseC_count.append(int(base.get(\"count\")))\n",
    "            countC = int(base.get(\"count\"))\n",
    "        if base.get(\"value\")==\"G\":\n",
    "            baseG_count.append(int(base.get(\"count\")))\n",
    "            countG = int(base.get(\"count\"))\n",
    "        if base.get(\"value\")==\"T\":\n",
    "            baseT_count.append(int(base.get(\"count\")))\n",
    "            countT = int(base.get(\"count\"))\n",
    "        if base.get(\"value\")==\"N\":\n",
    "            baseN_count.append(int(base.get(\"count\")))\n",
    "            countN = int(base.get(\"count\"))\n",
    "    gc_percent.append(float(countG+countC)/float(countC+countG+countA+countT))\n",
    "    qual_count = {}\n",
    "    for qual in run.find(\"Run\").find(\"QualityCount\").findall(\"Quality\"):\n",
    "        qual_count[qual.get(\"value\")] = int(qual.get(\"count\"))\n",
    "    read_quality_counts.append(qual_count)\n",
    "    \n",
    "max_index = total_num_reads.index(max(total_num_reads))\n",
    "\n",
    "run_ids_maxrun = run_ids[max_index]\n",
    "total_num_reads_maxrun = total_num_reads[max_index]\n",
    "total_num_bases_maxrun = total_num_bases[max_index]\n",
    "download_size_maxrun = download_size[max_index]\n",
    "avg_read_length_maxrun = avg_read_length[max_index]\n",
    "baseA_count_maxrun = baseA_count[max_index]\n",
    "baseC_count_maxrun = baseC_count[max_index]\n",
    "baseG_count_maxrun = baseG_count[max_index]\n",
    "baseT_count_maxrun = baseT_count[max_index]\n",
    "baseN_count_maxrun = baseN_count[max_index]\n",
    "gc_percent_maxrun = gc_percent[max_index]\n",
    "read_quality_counts_maxrun = read_quality_counts[max_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERR1462501\n",
      "25106994\n",
      "3138374250\n",
      "1163516874\n",
      "125.0\n",
      "859155672\n",
      "753913849\n",
      "654510698\n",
      "870745228\n",
      "48803\n",
      "0.448782183615\n",
      "{'27': 98304024, '14': 97672803, '22': 13830744, '33': 283013313, '37': 2619421880, '2': 26131486}\n",
      "['ERR1462501']\n",
      "[25106994]\n",
      "[3138374250]\n",
      "[1163516874]\n",
      "[125.0]\n",
      "[859155672]\n",
      "[753913849]\n",
      "[654510698]\n",
      "[870745228]\n",
      "[48803]\n",
      "[0.448782183615261]\n",
      "[{'27': 98304024, '14': 97672803, '22': 13830744, '33': 283013313, '37': 2619421880, '2': 26131486}]\n"
     ]
    }
   ],
   "source": [
    "print run_ids_maxrun\n",
    "print total_num_reads_maxrun\n",
    "print total_num_bases_maxrun\n",
    "print download_size_maxrun\n",
    "print avg_read_length_maxrun\n",
    "print baseA_count_maxrun\n",
    "print baseC_count_maxrun\n",
    "print baseG_count_maxrun\n",
    "print baseT_count_maxrun\n",
    "print baseN_count_maxrun\n",
    "print gc_percent_maxrun\n",
    "print read_quality_counts_maxrun\n",
    "\n",
    "print run_ids\n",
    "print total_num_reads\n",
    "print total_num_bases\n",
    "print download_size\n",
    "print avg_read_length\n",
    "print baseA_count\n",
    "print baseC_count\n",
    "print baseG_count\n",
    "print baseT_count\n",
    "print baseN_count\n",
    "print gc_percent\n",
    "print read_quality_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#asking for a friend - how many of the sra uids have elinks to biosample?\n",
    "elink_url = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=sra&db=biosample&tool=metaseq&email=metaseekcloud%40gmail.com'\n",
    "\n",
    "for key in batch_uid_list:\n",
    "    elink_url = elink_url+'&id='+str(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elink_url = 'https://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=sra&db=biosample&tool=metaseq&email=metaseekcloud%40gmail.com'\n",
    "for batch in batches:\n",
    "    print \"processing batch %s\" % batch\n",
    "    batch_uid_list = map(int,uid_list[batch[0]:batch[1]])\n",
    "\n",
    "    for key in batch_uid_list:\n",
    "        elink_url = elink_url+'&id='+str(key)\n",
    "    try:\n",
    "\n",
    "        e = urllib.urlopen(elink_url)\n",
    "        link_tree = etree.parse(e)\n",
    "        e.close()\n",
    "        link_xml = link_tree.getroot()\n",
    "        print link_xml\n",
    "    except etree.XMLSyntaxError, detail:\n",
    "        print detail.error_log\n",
    "\n",
    "    #note if there's no biosample link, <LinkSetDb> with <DbTo>=='biosample' just won't exist\n",
    "    biosample_ids = []\n",
    "    pubmed_ids = []\n",
    "    linksets = link_xml.findall(\"LinkSet\")\n",
    "    for link in linksets:\n",
    "        linkdb = link.findall(\"LinkSetDb\")\n",
    "        if len(linkdb)>0:\n",
    "            for db in linkdb:\n",
    "                if db.findtext(\"DbTo\")=='biosample':\n",
    "                    biosample_ids.append(int(db.find(\"Link\").findtext(\"Id\")))\n",
    "                if db.findtext(\"DbTo\")=='pubmed':\n",
    "                    pubmed_ids.append(int(db.find(\"Link\").findtext(\"Id\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'urllib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ff1bbb7f5c6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melink_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlink_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0metree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'urllib' is not defined"
     ]
    }
   ],
   "source": [
    "e = urllib.urlopen(elink_url)\n",
    "link_tree = etree.parse(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
